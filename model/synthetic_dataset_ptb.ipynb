{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Create Synthetic Dateset on Penn Treebank"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "92c05b1a0591f6a1"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "from collections import defaultdict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T08:10:55.627596Z",
     "start_time": "2024-01-15T08:10:55.085207Z"
    }
   },
   "id": "ded2974dd95dd4ce"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def read_sentences_with_pos_tags(path):\n",
    "    sentences_with_pos_tags = []\n",
    "\n",
    "    with open(path, 'r', encoding='utf-8') as file:\n",
    "        current_sentence = []\n",
    "        for line in file:\n",
    "            # Skip empty lines and comments\n",
    "            if line.strip() and not line.startswith('#'):\n",
    "                fields = line.split('\\t')\n",
    "                if len(fields) > 3:  # Ensure there are enough fields\n",
    "                    word = fields[1].lower()  # Word form is the second field\n",
    "                    upos = fields[3]  # Universal POS tag is the fourth field\n",
    "                    xpos = fields[4]  # Language specific POS tag is the fifth field\n",
    "                    current_sentence.append((word, upos, xpos))\n",
    "\n",
    "            # New sentence\n",
    "            elif current_sentence:\n",
    "                sentences_with_pos_tags.append(current_sentence)\n",
    "                current_sentence = []\n",
    "\n",
    "    return sentences_with_pos_tags"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T08:11:48.051498Z",
     "start_time": "2024-01-15T08:11:48.047162Z"
    }
   },
   "id": "70fbf6963dc61f51"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "file_path1 = '../data/ptb/penn-train.conllu'\n",
    "file_path2 = '../data/ptb/penn-test.conllu'\n",
    "file_path3 = '../data/ptb/penn-dev.conllu'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T08:11:49.534811Z",
     "start_time": "2024-01-15T08:11:49.531502Z"
    }
   },
   "id": "dbd67d483442e3ac"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39832\n"
     ]
    },
    {
     "data": {
      "text/plain": "[[('in', 'ADP', 'IN'),\n  ('an', 'DET', 'DT'),\n  ('oct.', 'PROPN', 'NNP'),\n  ('19', 'NUM', 'CD'),\n  ('review', 'NOUN', 'NN'),\n  ('of', 'ADP', 'IN'),\n  ('``', 'PUNCT', '``'),\n  ('the', 'DET', 'DT'),\n  ('misanthrope', 'NOUN', 'NN'),\n  (\"''\", 'PUNCT', \"''\"),\n  ('at', 'ADP', 'IN'),\n  ('chicago', 'PROPN', 'NNP'),\n  (\"'s\", 'PART', 'POS'),\n  ('goodman', 'PROPN', 'NNP'),\n  ('theatre', 'PROPN', 'NNP'),\n  ('-lrb-', 'PUNCT', '-LRB-'),\n  ('``', 'PUNCT', '``'),\n  ('revitalized', 'VERB', 'VBN'),\n  ('classics', 'NOUN', 'NNS'),\n  ('take', 'VERB', 'VBP'),\n  ('the', 'DET', 'DT'),\n  ('stage', 'NOUN', 'NN'),\n  ('in', 'ADP', 'IN'),\n  ('windy', 'PROPN', 'NNP'),\n  ('city', 'PROPN', 'NNP'),\n  (',', 'PUNCT', ','),\n  (\"''\", 'PUNCT', \"''\"),\n  ('leisure', 'NOUN', 'NN'),\n  ('&', 'CONJ', 'CC'),\n  ('arts', 'NOUN', 'NNS'),\n  ('-rrb-', 'PUNCT', '-RRB-'),\n  (',', 'PUNCT', ','),\n  ('the', 'DET', 'DT'),\n  ('role', 'NOUN', 'NN'),\n  ('of', 'ADP', 'IN'),\n  ('celimene', 'PROPN', 'NNP'),\n  (',', 'PUNCT', ','),\n  ('played', 'VERB', 'VBN'),\n  ('by', 'ADP', 'IN'),\n  ('kim', 'PROPN', 'NNP'),\n  ('cattrall', 'PROPN', 'NNP'),\n  (',', 'PUNCT', ','),\n  ('was', 'AUX', 'VBD'),\n  ('mistakenly', 'ADV', 'RB'),\n  ('attributed', 'VERB', 'VBN'),\n  ('to', 'ADP', 'TO'),\n  ('christina', 'PROPN', 'NNP'),\n  ('haag', 'PROPN', 'NNP'),\n  ('.', 'PUNCT', '.')],\n [('ms.', 'PROPN', 'NNP'),\n  ('haag', 'PROPN', 'NNP'),\n  ('plays', 'VERB', 'VBZ'),\n  ('elianti', 'PROPN', 'NNP'),\n  ('.', 'PUNCT', '.')],\n [('rolls-royce', 'PROPN', 'NNP'),\n  ('motor', 'PROPN', 'NNP'),\n  ('cars', 'PROPN', 'NNPS'),\n  ('inc.', 'PROPN', 'NNP'),\n  ('said', 'VERB', 'VBD'),\n  ('it', 'PRON', 'PRP'),\n  ('expects', 'VERB', 'VBZ'),\n  ('its', 'PRON', 'PRP$'),\n  ('u.s.', 'PROPN', 'NNP'),\n  ('sales', 'NOUN', 'NNS'),\n  ('to', 'PART', 'TO'),\n  ('remain', 'VERB', 'VB'),\n  ('steady', 'ADJ', 'JJ'),\n  ('at', 'ADP', 'IN'),\n  ('about', 'ADP', 'IN'),\n  ('1,200', 'NUM', 'CD'),\n  ('cars', 'NOUN', 'NNS'),\n  ('in', 'ADP', 'IN'),\n  ('1990', 'NUM', 'CD'),\n  ('.', 'PUNCT', '.')]]"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_pos_tags = read_sentences_with_pos_tags(file_path1)\n",
    "print(len(sentences_pos_tags))\n",
    "sentences_pos_tags[:3]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T08:11:51.725650Z",
     "start_time": "2024-01-15T08:11:51.066209Z"
    }
   },
   "id": "1d1783e8d11a2486"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def replace_low_frequency_words(sentences_with_pos_tags, filter_count=1):\n",
    "    # Count the frequencies of each word\n",
    "    word_counts = Counter(word for sentence in sentences_with_pos_tags for word, _, _ in sentence)\n",
    "\n",
    "    # Replace words with count less than filter_count to 'UNK' and their tags to 'UNK_TAG'\n",
    "    processed_sentences = []\n",
    "    for sentence in sentences_with_pos_tags:\n",
    "        new_sentence = []\n",
    "        for word, upos, xpos in sentence:\n",
    "            if word_counts[word] < filter_count:\n",
    "                new_word = 'UNK'\n",
    "                new_upos = 'UNK_TAG'\n",
    "                new_xpos = 'UNK_TAG'\n",
    "            else:\n",
    "                new_word = word\n",
    "                new_upos = upos\n",
    "                new_xpos = xpos\n",
    "            new_sentence.append((new_word, new_upos, new_xpos))\n",
    "        processed_sentences.append(new_sentence)\n",
    "\n",
    "    return processed_sentences"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T08:11:53.276874Z",
     "start_time": "2024-01-15T08:11:53.254877Z"
    }
   },
   "id": "64552bda6752f35c"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "[[('in', 'ADP', 'IN'),\n  ('an', 'DET', 'DT'),\n  ('oct.', 'PROPN', 'NNP'),\n  ('19', 'NUM', 'CD'),\n  ('review', 'NOUN', 'NN'),\n  ('of', 'ADP', 'IN'),\n  ('``', 'PUNCT', '``'),\n  ('the', 'DET', 'DT'),\n  ('UNK', 'UNK_TAG', 'UNK_TAG'),\n  (\"''\", 'PUNCT', \"''\"),\n  ('at', 'ADP', 'IN'),\n  ('chicago', 'PROPN', 'NNP'),\n  (\"'s\", 'PART', 'POS'),\n  ('UNK', 'UNK_TAG', 'UNK_TAG'),\n  ('UNK', 'UNK_TAG', 'UNK_TAG'),\n  ('-lrb-', 'PUNCT', '-LRB-'),\n  ('``', 'PUNCT', '``'),\n  ('UNK', 'UNK_TAG', 'UNK_TAG'),\n  ('UNK', 'UNK_TAG', 'UNK_TAG'),\n  ('take', 'VERB', 'VBP'),\n  ('the', 'DET', 'DT'),\n  ('stage', 'NOUN', 'NN'),\n  ('in', 'ADP', 'IN'),\n  ('UNK', 'UNK_TAG', 'UNK_TAG'),\n  ('city', 'PROPN', 'NNP'),\n  (',', 'PUNCT', ','),\n  (\"''\", 'PUNCT', \"''\"),\n  ('UNK', 'UNK_TAG', 'UNK_TAG'),\n  ('&', 'CONJ', 'CC'),\n  ('UNK', 'UNK_TAG', 'UNK_TAG'),\n  ('-rrb-', 'PUNCT', '-RRB-'),\n  (',', 'PUNCT', ','),\n  ('the', 'DET', 'DT'),\n  ('role', 'NOUN', 'NN'),\n  ('of', 'ADP', 'IN'),\n  ('UNK', 'UNK_TAG', 'UNK_TAG'),\n  (',', 'PUNCT', ','),\n  ('played', 'VERB', 'VBN'),\n  ('by', 'ADP', 'IN'),\n  ('UNK', 'UNK_TAG', 'UNK_TAG'),\n  ('UNK', 'UNK_TAG', 'UNK_TAG'),\n  (',', 'PUNCT', ','),\n  ('was', 'AUX', 'VBD'),\n  ('UNK', 'UNK_TAG', 'UNK_TAG'),\n  ('attributed', 'VERB', 'VBN'),\n  ('to', 'ADP', 'TO'),\n  ('UNK', 'UNK_TAG', 'UNK_TAG'),\n  ('UNK', 'UNK_TAG', 'UNK_TAG'),\n  ('.', 'PUNCT', '.')],\n [('ms.', 'PROPN', 'NNP'),\n  ('UNK', 'UNK_TAG', 'UNK_TAG'),\n  ('plays', 'VERB', 'VBZ'),\n  ('UNK', 'UNK_TAG', 'UNK_TAG'),\n  ('.', 'PUNCT', '.')],\n [('UNK', 'UNK_TAG', 'UNK_TAG'),\n  ('motor', 'PROPN', 'NNP'),\n  ('cars', 'PROPN', 'NNPS'),\n  ('inc.', 'PROPN', 'NNP'),\n  ('said', 'VERB', 'VBD'),\n  ('it', 'PRON', 'PRP'),\n  ('expects', 'VERB', 'VBZ'),\n  ('its', 'PRON', 'PRP$'),\n  ('u.s.', 'PROPN', 'NNP'),\n  ('sales', 'NOUN', 'NNS'),\n  ('to', 'PART', 'TO'),\n  ('remain', 'VERB', 'VB'),\n  ('steady', 'ADJ', 'JJ'),\n  ('at', 'ADP', 'IN'),\n  ('about', 'ADP', 'IN'),\n  ('UNK', 'UNK_TAG', 'UNK_TAG'),\n  ('cars', 'NOUN', 'NNS'),\n  ('in', 'ADP', 'IN'),\n  ('1990', 'NUM', 'CD'),\n  ('.', 'PUNCT', '.')]]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_sentences = replace_low_frequency_words(sentences_pos_tags, filter_count=20)\n",
    "filtered_sentences[:3]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T08:11:54.816105Z",
     "start_time": "2024-01-15T08:11:54.584170Z"
    }
   },
   "id": "519fa300c7c1ea65"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "def create_vocab_index(sentences_with_pos_tags):\n",
    "    # Function to create a dictionary mapping each unique word/POS to an integer index\n",
    "    # with specified start index\n",
    "    def build_index(items, start_index=0):\n",
    "        item_to_index = defaultdict(lambda: len(item_to_index) + start_index)\n",
    "        for item in items:\n",
    "            item_to_index[item]\n",
    "        return dict(item_to_index)\n",
    "\n",
    "    # Flatten the list of sentences to get a single list of words and POS tags\n",
    "    all_words = [word for sentence in sentences_with_pos_tags for word, upos, xpos in sentence]\n",
    "    all_upos_tags = [upos for sentence in sentences_with_pos_tags for word, upos, xpos in sentence]\n",
    "    all_xpos_tags = [xpos for sentence in sentences_with_pos_tags for word, upos, xpos in sentence]\n",
    "\n",
    "    return build_index(all_words, start_index=0), build_index(all_upos_tags, start_index=1),  build_index(all_xpos_tags, start_index=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T08:43:27.834596Z",
     "start_time": "2024-01-15T08:43:27.820111Z"
    }
   },
   "id": "f1857d0c82ac9ab7"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4110\n"
     ]
    },
    {
     "data": {
      "text/plain": "([('at', 10), ('chicago', 11), (\"'s\", 12), ('-lrb-', 13), ('take', 14)],\n [('ADP', 1), ('DET', 2), ('PROPN', 3), ('NUM', 4), ('NOUN', 5)],\n [('IN', 1), ('DT', 2), ('NNP', 3), ('CD', 4), ('NN', 5)])"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_index, upos_to_index, xpos_to_index = create_vocab_index(filtered_sentences)\n",
    "print(len(word_to_index))\n",
    "list(word_to_index.items())[10:15], list(upos_to_index.items())[:5], list(xpos_to_index.items())[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T08:43:28.971780Z",
     "start_time": "2024-01-15T08:43:28.842027Z"
    }
   },
   "id": "627926987e0430ce"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "(4110, 18, 46)"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_to_index), len(upos_to_index), len(xpos_to_index)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T08:43:30.532397Z",
     "start_time": "2024-01-15T08:43:30.514469Z"
    }
   },
   "id": "45b9d3235e2411f7"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "def convert_to_indexes(filtered_sentences_tags, word_to_index, upos_to_index, xpos_to_index):\n",
    "    hidden_states_universal = []\n",
    "    hidden_states_specific = []\n",
    "    observations = []\n",
    "\n",
    "    for sentence in filtered_sentences_tags:\n",
    "        if len(sentence) <= 5: \n",
    "            continue\n",
    "        sentence_upos_indexes = [upos_to_index[upos] for _, upos, _ in sentence]\n",
    "        sentence_xpos_indexes = [xpos_to_index[xpos] for _, _, xpos in sentence]\n",
    "        sentence_word_indexes = [word_to_index[word] for word, _, _ in sentence]\n",
    "\n",
    "        hidden_states_universal.append(sentence_upos_indexes)\n",
    "        hidden_states_specific.append(sentence_xpos_indexes)\n",
    "        observations.append(sentence_word_indexes)\n",
    "\n",
    "    return hidden_states_universal, hidden_states_specific, observations"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T08:43:31.730129Z",
     "start_time": "2024-01-15T08:43:31.711879Z"
    }
   },
   "id": "d99468136e414171"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "hidden_states_universal, hidden_states_specific, observations = convert_to_indexes(\n",
    "    filtered_sentences, word_to_index, upos_to_index, xpos_to_index)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T08:43:33.272480Z",
     "start_time": "2024-01-15T08:43:33.152633Z"
    }
   },
   "id": "75c511c19f12c211"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 1, 6, 2, 7, 6, 1, 3, 8, 7, 7, 6, 6, 7, 7, 9, 2, 5, 1, 7, 3, 6, 6, 7, 10, 7, 6, 6, 2, 5, 1, 7, 6, 9, 1, 7, 7, 6, 11, 7, 9, 1, 7, 7, 6]\n",
      "[1, 2, 3, 4, 5, 1, 6, 2, 7, 8, 1, 3, 9, 7, 7, 10, 6, 7, 7, 11, 2, 5, 1, 7, 3, 12, 8, 7, 13, 7, 14, 12, 2, 5, 1, 7, 12, 15, 1, 7, 7, 12, 16, 7, 15, 17, 7, 7, 18]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 8, 8, 13, 6, 8, 8, 14, 7, 15, 0, 8, 16, 17, 9, 8, 18, 8, 19, 17, 7, 20, 5, 8, 17, 21, 22, 8, 8, 17, 23, 8, 24, 25, 8, 8, 26]\n",
      "-----------------------------\n",
      "[7, 3, 3, 3, 9, 12, 9, 12, 3, 5, 8, 9, 13, 1, 1, 7, 5, 1, 4, 6]\n",
      "[7, 3, 20, 3, 16, 21, 19, 22, 3, 23, 17, 24, 25, 1, 1, 7, 23, 1, 4, 18]\n",
      "[8, 29, 30, 31, 32, 33, 34, 35, 36, 37, 25, 38, 39, 10, 40, 8, 30, 0, 41, 26]\n",
      "-----------------------------\n",
      "[2, 5, 5, 5, 13, 5, 9, 7, 5, 1, 2, 3]\n",
      "[2, 5, 5, 5, 25, 5, 16, 7, 23, 1, 2, 3]\n",
      "[7, 42, 43, 44, 45, 46, 47, 8, 30, 0, 7, 36]\n",
      "-----------------------------\n",
      "[3, 7, 6, 5, 10, 13, 5, 5, 6, 9, 12, 7, 5, 1, 2, 5, 5, 5, 1, 3, 10, 3, 6, 10, 1, 13, 13, 5, 6]\n",
      "[3, 7, 12, 5, 13, 25, 5, 5, 12, 16, 21, 7, 5, 1, 2, 5, 5, 5, 1, 3, 13, 3, 12, 13, 1, 25, 25, 23, 18]\n",
      "[48, 8, 17, 49, 50, 51, 52, 53, 17, 32, 54, 8, 55, 56, 7, 42, 43, 44, 0, 57, 50, 58, 17, 50, 0, 59, 60, 61, 26]\n",
      "-----------------------------\n",
      "[3, 3, 3, 9, 12, 5, 1, 4, 5, 1, 4, 5, 2, 5, 6]\n",
      "[3, 3, 3, 16, 22, 5, 17, 4, 23, 1, 4, 23, 2, 5, 18]\n",
      "[62, 63, 31, 64, 35, 65, 25, 66, 67, 68, 69, 67, 70, 71, 26]\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "for index in range(len(observations[:5])):\n",
    "    print('[' + ', '.join(map(str, hidden_states_universal[:5][index])) + ']')\n",
    "    print('[' + ', '.join(map(str, hidden_states_specific[:5][index])) + ']')\n",
    "    print('[' + ', '.join(map(str, observations[:5][index])) + ']')\n",
    "    print('-----------------------------')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T08:43:35.348125Z",
     "start_time": "2024-01-15T08:43:35.302086Z"
    }
   },
   "id": "535f784c8912985"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "def add_noise_to_states_ptb(hidden_states, number_states, flip_prob=0.5):\n",
    "    noisy_hidden_states = []\n",
    "    for sequence in hidden_states:\n",
    "        noisy_sequence = []\n",
    "        for state in sequence:\n",
    "            if np.random.rand() < flip_prob:\n",
    "                # Flip the state to a different random state\n",
    "                possible_states = list(range(1, number_states + 1))\n",
    "                possible_states.remove(state)  # Remove the current state from possibilities\n",
    "                new_state = np.random.choice(possible_states)\n",
    "                noisy_sequence.append(new_state)\n",
    "            else:\n",
    "                noisy_sequence.append(state)\n",
    "        noisy_hidden_states.append(noisy_sequence)\n",
    "    return noisy_hidden_states"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T08:43:49.396360Z",
     "start_time": "2024-01-15T08:43:49.393422Z"
    }
   },
   "id": "5a00b40d28c4a0a9"
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "ptb_noisy_level = 0.3\n",
    "noisy_hidden_states_universal = add_noise_to_states_ptb(hidden_states_universal, len(upos_to_index), flip_prob=ptb_noisy_level)\n",
    "noisy_hidden_states_specific = add_noise_to_states_ptb(hidden_states_specific, len(xpos_to_index), flip_prob=ptb_noisy_level)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T08:43:53.248260Z",
     "start_time": "2024-01-15T08:43:50.308589Z"
    }
   },
   "id": "882f45144c8d7d64"
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "for i in range(len(hidden_states_universal)):\n",
    "    hidden_states_universal[i].insert(0, 0)\n",
    "    noisy_hidden_states_universal[i].insert(0, 0)\n",
    "\n",
    "    hidden_states_specific[i].insert(0, 0)\n",
    "    noisy_hidden_states_specific[i].insert(0, 0)\n",
    "    \n",
    "    observations[i].insert(0, -1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T08:43:54.173749Z",
     "start_time": "2024-01-15T08:43:54.169318Z"
    }
   },
   "id": "bb61f6c5a8ed226b"
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 1, 6, 2, 7, 6, 1, 3, 8, 7, 7, 6, 6, 7, 7, 9, 2, 5, 1, 7, 3, 6, 6, 7, 10, 7, 6, 6, 2, 5, 1, 7, 6, 9, 1, 7, 7, 6, 11, 7, 9, 1, 7, 7, 6]\n",
      "[0, 8, 2, 3, 4, 5, 1, 6, 2, 7, 10, 15, 3, 5, 2, 7, 11, 4, 3, 13, 9, 3, 10, 14, 17, 3, 6, 6, 7, 10, 7, 16, 6, 2, 5, 1, 7, 7, 9, 1, 13, 7, 9, 11, 7, 9, 1, 14, 7, 6]\n",
      "-----------------------------\n",
      "[0, 7, 3, 3, 3, 9, 12, 9, 12, 3, 5, 8, 9, 13, 1, 1, 7, 5, 1, 4, 6]\n",
      "[0, 7, 3, 18, 3, 9, 15, 9, 12, 3, 14, 8, 9, 17, 16, 3, 7, 5, 1, 7, 6]\n",
      "-----------------------------\n",
      "[0, 2, 5, 5, 5, 13, 5, 9, 7, 5, 1, 2, 3]\n",
      "[0, 2, 5, 3, 2, 13, 11, 13, 7, 8, 1, 2, 3]\n",
      "-----------------------------\n",
      "[0, 3, 7, 6, 5, 10, 13, 5, 5, 6, 9, 12, 7, 5, 1, 2, 5, 5, 5, 1, 3, 10, 3, 6, 10, 1, 13, 13, 5, 6]\n",
      "[0, 3, 7, 6, 5, 12, 13, 5, 5, 6, 9, 12, 7, 1, 1, 2, 5, 5, 5, 1, 6, 10, 3, 11, 10, 1, 13, 13, 5, 6]\n",
      "-----------------------------\n",
      "[0, 3, 3, 3, 9, 12, 5, 1, 4, 5, 1, 4, 5, 2, 5, 6]\n",
      "[0, 3, 3, 2, 7, 12, 5, 1, 4, 5, 1, 3, 10, 10, 5, 1]\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "for index in range(len(observations[20:25])):\n",
    "    print('[' + ', '.join(map(str, hidden_states_universal[:5][index])) + ']')\n",
    "    print('[' + ', '.join(map(str, noisy_hidden_states_universal[:5][index])) + ']')\n",
    "    print('-----------------------------')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T08:43:55.092568Z",
     "start_time": "2024-01-15T08:43:55.077629Z"
    }
   },
   "id": "7268fce90a40c6f1"
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 1, 6, 2, 7, 8, 1, 3, 9, 7, 7, 10, 6, 7, 7, 11, 2, 5, 1, 7, 3, 12, 8, 7, 13, 7, 14, 12, 2, 5, 1, 7, 12, 15, 1, 7, 7, 12, 16, 7, 15, 17, 7, 7, 18]\n",
      "[0, 1, 20, 3, 20, 5, 1, 6, 2, 7, 8, 33, 3, 9, 7, 7, 10, 6, 7, 7, 17, 2, 5, 26, 7, 3, 28, 44, 7, 14, 7, 41, 12, 2, 5, 1, 7, 16, 16, 8, 7, 7, 12, 16, 22, 15, 22, 7, 7, 18]\n",
      "-----------------------------\n",
      "[0, 7, 3, 20, 3, 16, 21, 19, 22, 3, 23, 17, 24, 25, 1, 1, 7, 23, 1, 4, 18]\n",
      "[0, 7, 3, 20, 3, 42, 21, 19, 36, 3, 23, 17, 24, 27, 1, 46, 4, 39, 1, 13, 18]\n",
      "-----------------------------\n",
      "[0, 2, 5, 5, 5, 25, 5, 16, 7, 23, 1, 2, 3]\n",
      "[0, 2, 5, 5, 36, 25, 30, 16, 7, 23, 1, 2, 24]\n",
      "-----------------------------\n",
      "[0, 3, 7, 12, 5, 13, 25, 5, 5, 12, 16, 21, 7, 5, 1, 2, 5, 5, 5, 1, 3, 13, 3, 12, 13, 1, 25, 25, 23, 18]\n",
      "[0, 3, 7, 12, 15, 13, 25, 5, 5, 12, 16, 21, 7, 5, 1, 19, 5, 44, 43, 1, 3, 27, 3, 12, 35, 1, 22, 39, 21, 18]\n",
      "-----------------------------\n",
      "[0, 3, 3, 3, 16, 22, 5, 17, 4, 23, 1, 4, 23, 2, 5, 18]\n",
      "[0, 3, 3, 19, 16, 11, 5, 10, 4, 21, 6, 4, 6, 2, 10, 18]\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "for index in range(len(observations[:5])):\n",
    "    print('[' + ', '.join(map(str, hidden_states_specific[:5][index])) + ']')\n",
    "    print('[' + ', '.join(map(str, noisy_hidden_states_specific[:5][index])) + ']')\n",
    "    print('-----------------------------')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T08:44:16.255593Z",
     "start_time": "2024-01-15T08:44:16.243041Z"
    }
   },
   "id": "80f31f2fc3b2a95b"
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 8, 8, 13, 6, 8, 8, 14, 7, 15, 0, 8, 16, 17, 9, 8, 18, 8, 19, 17, 7, 20, 5, 8, 17, 21, 22, 8, 8, 17, 23, 8, 24, 25, 8, 8, 26]\n",
      "-----------------------------\n",
      "[-1, 8, 29, 30, 31, 32, 33, 34, 35, 36, 37, 25, 38, 39, 10, 40, 8, 30, 0, 41, 26]\n",
      "-----------------------------\n",
      "[-1, 7, 42, 43, 44, 45, 46, 47, 8, 30, 0, 7, 36]\n",
      "-----------------------------\n",
      "[-1, 48, 8, 17, 49, 50, 51, 52, 53, 17, 32, 54, 8, 55, 56, 7, 42, 43, 44, 0, 57, 50, 58, 17, 50, 0, 59, 60, 61, 26]\n",
      "-----------------------------\n",
      "[-1, 62, 63, 31, 64, 35, 65, 25, 66, 67, 68, 69, 67, 70, 71, 26]\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "for index in range(len(observations[:5])):\n",
    "    print('[' + ', '.join(map(str, observations[:5][index])) + ']')\n",
    "    print('-----------------------------')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T08:44:21.348092Z",
     "start_time": "2024-01-15T08:44:21.345215Z"
    }
   },
   "id": "fc3fe53ff9d663a"
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "file_path = f\"../data/PennTreebank_synthetic_dataset(noise-{ptb_noisy_level}).npz\"\n",
    "obs_object = np.array(observations, dtype=object)\n",
    "uni_hid_object = np.array(hidden_states_universal, dtype=object)\n",
    "noisy_uni_hid_object = np.array(noisy_hidden_states_universal, dtype=object)\n",
    "spc_hid_object = np.array(hidden_states_specific, dtype=object)\n",
    "noisy_spc_hid_object = np.array(noisy_hidden_states_specific, dtype=object)\n",
    "np.savez(file_path, num_states=len(upos_to_index) + 1, num_obs=len(word_to_index), observation=obs_object, real_hidden_universal=uni_hid_object, noisy_hidden_universal=noisy_uni_hid_object, real_hidden_specific=spc_hid_object, noisy_hidden_specifc=noisy_spc_hid_object, noisy_level=ptb_noisy_level)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T08:44:34.155941Z",
     "start_time": "2024-01-15T08:44:33.373491Z"
    }
   },
   "id": "9da93b0a5f4dbd12"
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "(array(4110), array(19))"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_npz = np.load(\"../data/PennTreebank_synthetic_dataset(noise-0.3).npz\")\n",
    "read_npz['num_obs'], read_npz['num_states']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T08:44:34.857026Z",
     "start_time": "2024-01-15T08:44:34.837480Z"
    }
   },
   "id": "6d6feaa2629c902b"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "7"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upos_to_index['UNK_TAG']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T08:40:06.131582Z",
     "start_time": "2024-01-15T08:40:06.120783Z"
    }
   },
   "id": "3a704269a47fb374"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
