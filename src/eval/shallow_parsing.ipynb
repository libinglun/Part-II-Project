{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-26T14:54:07.158170Z",
     "start_time": "2024-02-26T14:54:07.156424Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from nltk.tag.perceptron import PerceptronTagger\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [],
   "source": [
    "tagger = PerceptronTagger()\n",
    "tagset = 'universal'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T14:54:18.142695Z",
     "start_time": "2024-02-26T14:54:18.128395Z"
    }
   },
   "id": "8fc4236877ed4dce"
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [],
   "source": [
    "def read_sentences_with_pos_tags(path):\n",
    "    sentences_with_pos_tags = []\n",
    "\n",
    "    with open(path, 'r', encoding='utf-8') as file:\n",
    "        current_sentence = []\n",
    "        for line in file:\n",
    "            line = line.replace('\\n', '')                   # Eliminate all \\n\n",
    "            if line.strip() and not line.startswith('#'):   # Skip empty lines and comments\n",
    "                fields = line.split(' ')\n",
    "                word = fields[0].lower()        \n",
    "                xpos = nltk.tag._pos_tag([word], tagset, tagger, lang='eng')[0][1]\n",
    "                chunk = fields[2]                        \n",
    "                current_sentence.append((word, xpos, chunk))\n",
    "            elif current_sentence:\n",
    "                sentences_with_pos_tags.append(current_sentence)\n",
    "                current_sentence = []\n",
    "\n",
    "    return sentences_with_pos_tags"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T14:54:58.193329Z",
     "start_time": "2024-02-26T14:54:58.175670Z"
    }
   },
   "id": "7d7f829e4de66998"
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [],
   "source": [
    "path = \"../../data/chunking/train.txt\"\n",
    "sentences = read_sentences_with_pos_tags(path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T14:55:04.357195Z",
     "start_time": "2024-02-26T14:55:00.301863Z"
    }
   },
   "id": "1b89ebca4404721b"
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [
    {
     "data": {
      "text/plain": "[[('confidence', 'NOUN', 'B-NP'),\n  ('in', 'ADP', 'B-PP'),\n  ('the', 'DET', 'B-NP'),\n  ('pound', 'NOUN', 'I-NP'),\n  ('is', 'VERB', 'B-VP'),\n  ('widely', 'ADV', 'I-VP'),\n  ('expected', 'VERB', 'I-VP'),\n  ('to', 'PRT', 'I-VP'),\n  ('take', 'VERB', 'I-VP'),\n  ('another', 'DET', 'B-NP'),\n  ('sharp', 'ADJ', 'I-NP'),\n  ('dive', 'NOUN', 'I-NP'),\n  ('if', 'ADP', 'B-SBAR'),\n  ('trade', 'NOUN', 'B-NP'),\n  ('figures', 'NOUN', 'I-NP'),\n  ('for', 'ADP', 'B-PP'),\n  ('september', 'NOUN', 'B-NP'),\n  (',', '.', 'O'),\n  ('due', 'ADJ', 'B-ADJP'),\n  ('for', 'ADP', 'B-PP'),\n  ('release', 'NOUN', 'B-NP'),\n  ('tomorrow', 'NOUN', 'B-NP'),\n  (',', '.', 'O'),\n  ('fail', 'NOUN', 'B-VP'),\n  ('to', 'PRT', 'I-VP'),\n  ('show', 'NOUN', 'I-VP'),\n  ('a', 'DET', 'B-NP'),\n  ('substantial', 'ADJ', 'I-NP'),\n  ('improvement', 'NOUN', 'I-NP'),\n  ('from', 'ADP', 'B-PP'),\n  ('july', 'NOUN', 'B-NP'),\n  ('and', 'CONJ', 'I-NP'),\n  ('august', 'NOUN', 'I-NP'),\n  (\"'s\", 'PRT', 'B-NP'),\n  ('near-record', 'NOUN', 'I-NP'),\n  ('deficits', 'NOUN', 'I-NP'),\n  ('.', '.', 'O')],\n [('chancellor', 'NOUN', 'O'),\n  ('of', 'ADP', 'B-PP'),\n  ('the', 'DET', 'B-NP'),\n  ('exchequer', 'NOUN', 'I-NP'),\n  ('nigel', 'NOUN', 'B-NP'),\n  ('lawson', 'NOUN', 'I-NP'),\n  (\"'s\", 'PRT', 'B-NP'),\n  ('restated', 'VERB', 'I-NP'),\n  ('commitment', 'NOUN', 'I-NP'),\n  ('to', 'PRT', 'B-PP'),\n  ('a', 'DET', 'B-NP'),\n  ('firm', 'NOUN', 'I-NP'),\n  ('monetary', 'ADJ', 'I-NP'),\n  ('policy', 'NOUN', 'I-NP'),\n  ('has', 'VERB', 'B-VP'),\n  ('helped', 'VERB', 'I-VP'),\n  ('to', 'PRT', 'I-VP'),\n  ('prevent', 'NOUN', 'I-VP'),\n  ('a', 'DET', 'B-NP'),\n  ('freefall', 'NOUN', 'I-NP'),\n  ('in', 'ADP', 'B-PP'),\n  ('sterling', 'NOUN', 'B-NP'),\n  ('over', 'ADP', 'B-PP'),\n  ('the', 'DET', 'B-NP'),\n  ('past', 'NOUN', 'I-NP'),\n  ('week', 'NOUN', 'I-NP'),\n  ('.', '.', 'O')],\n [('but', 'CONJ', 'O'),\n  ('analysts', 'NOUN', 'B-NP'),\n  ('reckon', 'NOUN', 'B-VP'),\n  ('underlying', 'VERB', 'B-NP'),\n  ('support', 'NOUN', 'I-NP'),\n  ('for', 'ADP', 'B-PP'),\n  ('sterling', 'NOUN', 'B-NP'),\n  ('has', 'VERB', 'B-VP'),\n  ('been', 'VERB', 'I-VP'),\n  ('eroded', 'VERB', 'I-VP'),\n  ('by', 'ADP', 'B-PP'),\n  ('the', 'DET', 'B-NP'),\n  ('chancellor', 'NOUN', 'I-NP'),\n  (\"'s\", 'PRT', 'B-NP'),\n  ('failure', 'NOUN', 'I-NP'),\n  ('to', 'PRT', 'B-VP'),\n  ('announce', 'NOUN', 'I-VP'),\n  ('any', 'DET', 'B-NP'),\n  ('new', 'ADJ', 'I-NP'),\n  ('policy', 'NOUN', 'I-NP'),\n  ('measures', 'NOUN', 'I-NP'),\n  ('in', 'ADP', 'B-PP'),\n  ('his', 'PRON', 'B-NP'),\n  ('mansion', 'NOUN', 'I-NP'),\n  ('house', 'NOUN', 'I-NP'),\n  ('speech', 'NOUN', 'I-NP'),\n  ('last', 'ADJ', 'B-NP'),\n  ('thursday', 'NOUN', 'I-NP'),\n  ('.', '.', 'O')],\n [('this', 'DET', 'B-NP'),\n  ('has', 'VERB', 'B-VP'),\n  ('increased', 'VERB', 'I-VP'),\n  ('the', 'DET', 'B-NP'),\n  ('risk', 'NOUN', 'I-NP'),\n  ('of', 'ADP', 'B-PP'),\n  ('the', 'DET', 'B-NP'),\n  ('government', 'NOUN', 'I-NP'),\n  ('being', 'VERB', 'B-VP'),\n  ('forced', 'VERB', 'I-VP'),\n  ('to', 'PRT', 'I-VP'),\n  ('increase', 'NOUN', 'I-VP'),\n  ('base', 'NOUN', 'B-NP'),\n  ('rates', 'NOUN', 'I-NP'),\n  ('to', 'PRT', 'B-PP'),\n  ('16', 'NUM', 'B-NP'),\n  ('%', 'NOUN', 'I-NP'),\n  ('from', 'ADP', 'B-PP'),\n  ('their', 'PRON', 'B-NP'),\n  ('current', 'ADJ', 'I-NP'),\n  ('15', 'NUM', 'I-NP'),\n  ('%', 'NOUN', 'I-NP'),\n  ('level', 'NOUN', 'I-NP'),\n  ('to', 'PRT', 'B-VP'),\n  ('defend', 'NOUN', 'I-VP'),\n  ('the', 'DET', 'B-NP'),\n  ('pound', 'NOUN', 'I-NP'),\n  (',', '.', 'O'),\n  ('economists', 'NOUN', 'B-NP'),\n  ('and', 'CONJ', 'O'),\n  ('foreign', 'ADJ', 'B-NP'),\n  ('exchange', 'NOUN', 'I-NP'),\n  ('market', 'NOUN', 'I-NP'),\n  ('analysts', 'NOUN', 'I-NP'),\n  ('say', 'VERB', 'B-VP'),\n  ('.', '.', 'O')],\n [('``', '.', 'O'),\n  ('the', 'DET', 'B-NP'),\n  ('risks', 'NOUN', 'I-NP'),\n  ('for', 'ADP', 'B-PP'),\n  ('sterling', 'NOUN', 'B-NP'),\n  ('of', 'ADP', 'B-PP'),\n  ('a', 'DET', 'B-NP'),\n  ('bad', 'ADJ', 'I-NP'),\n  ('trade', 'NOUN', 'I-NP'),\n  ('figure', 'NOUN', 'I-NP'),\n  ('are', 'VERB', 'B-VP'),\n  ('very', 'ADV', 'B-ADVP'),\n  ('heavily', 'ADV', 'I-ADVP'),\n  ('on', 'ADP', 'B-PP'),\n  ('the', 'DET', 'B-NP'),\n  ('down', 'ADV', 'I-NP'),\n  ('side', 'NOUN', 'I-NP'),\n  (',', '.', 'O'),\n  (\"''\", '.', 'O'),\n  ('said', 'VERB', 'B-VP'),\n  ('chris', 'NOUN', 'B-NP'),\n  ('dillow', 'NOUN', 'I-NP'),\n  (',', '.', 'O'),\n  ('senior', 'ADJ', 'B-NP'),\n  ('u.k.', 'NOUN', 'I-NP'),\n  ('economist', 'NOUN', 'I-NP'),\n  ('at', 'ADP', 'B-PP'),\n  ('nomura', 'NOUN', 'B-NP'),\n  ('research', 'NOUN', 'I-NP'),\n  ('institute', 'NOUN', 'I-NP'),\n  ('.', '.', 'O')]]"
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T15:03:02.817270Z",
     "start_time": "2024-02-26T15:03:02.807936Z"
    }
   },
   "id": "e66d31b429f40bba"
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [],
   "source": [
    "def replace_low_frequency_words(sentences_with_pos_tags, filter_count=1):\n",
    "    # Count the frequencies of each word\n",
    "    word_counts = Counter(word for sentence in sentences_with_pos_tags for word, _, _ in sentence)\n",
    "\n",
    "    # Replace words with count less than filter_count to 'UNK' and their tags to 'UNK_TAG'\n",
    "    processed_sentences = []\n",
    "    for sentence in sentences_with_pos_tags:\n",
    "        new_sentence = []\n",
    "        for word, xpos, chunk in sentence:\n",
    "            if word_counts[word] < filter_count:\n",
    "                new_word = 'UNK'                # Only set the word to UNK\n",
    "                new_xpos = 'UNK'\n",
    "            else:\n",
    "                new_word = word\n",
    "                new_xpos = xpos\n",
    "            new_sentence.append((new_word, new_xpos, chunk))\n",
    "        processed_sentences.append(new_sentence)\n",
    "\n",
    "    return processed_sentences"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T14:55:12.130710Z",
     "start_time": "2024-02-26T14:55:12.118743Z"
    }
   },
   "id": "51035f5b991a5da5"
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [
    {
     "data": {
      "text/plain": "[[('confidence', 'NOUN', 'B-NP'),\n  ('in', 'ADP', 'B-PP'),\n  ('the', 'DET', 'B-NP'),\n  ('pound', 'NOUN', 'I-NP'),\n  ('is', 'VERB', 'B-VP'),\n  ('widely', 'ADV', 'I-VP'),\n  ('expected', 'VERB', 'I-VP'),\n  ('to', 'PRT', 'I-VP'),\n  ('take', 'VERB', 'I-VP'),\n  ('another', 'DET', 'B-NP'),\n  ('sharp', 'ADJ', 'I-NP'),\n  ('dive', 'NOUN', 'I-NP'),\n  ('if', 'ADP', 'B-SBAR'),\n  ('trade', 'NOUN', 'B-NP'),\n  ('figures', 'NOUN', 'I-NP'),\n  ('for', 'ADP', 'B-PP'),\n  ('september', 'NOUN', 'B-NP'),\n  (',', '.', 'O'),\n  ('due', 'ADJ', 'B-ADJP'),\n  ('for', 'ADP', 'B-PP'),\n  ('release', 'NOUN', 'B-NP'),\n  ('tomorrow', 'NOUN', 'B-NP'),\n  (',', '.', 'O'),\n  ('fail', 'NOUN', 'B-VP'),\n  ('to', 'PRT', 'I-VP'),\n  ('show', 'NOUN', 'I-VP'),\n  ('a', 'DET', 'B-NP'),\n  ('substantial', 'ADJ', 'I-NP'),\n  ('improvement', 'NOUN', 'I-NP'),\n  ('from', 'ADP', 'B-PP'),\n  ('july', 'NOUN', 'B-NP'),\n  ('and', 'CONJ', 'I-NP'),\n  ('august', 'NOUN', 'I-NP'),\n  (\"'s\", 'PRT', 'B-NP'),\n  ('UNK', 'UNK', 'I-NP'),\n  ('UNK', 'UNK', 'I-NP'),\n  ('.', '.', 'O')],\n [('chancellor', 'NOUN', 'O'),\n  ('of', 'ADP', 'B-PP'),\n  ('the', 'DET', 'B-NP'),\n  ('exchequer', 'NOUN', 'I-NP'),\n  ('nigel', 'NOUN', 'B-NP'),\n  ('lawson', 'NOUN', 'I-NP'),\n  (\"'s\", 'PRT', 'B-NP'),\n  ('restated', 'VERB', 'I-NP'),\n  ('commitment', 'NOUN', 'I-NP'),\n  ('to', 'PRT', 'B-PP'),\n  ('a', 'DET', 'B-NP'),\n  ('firm', 'NOUN', 'I-NP'),\n  ('monetary', 'ADJ', 'I-NP'),\n  ('policy', 'NOUN', 'I-NP'),\n  ('has', 'VERB', 'B-VP'),\n  ('helped', 'VERB', 'I-VP'),\n  ('to', 'PRT', 'I-VP'),\n  ('prevent', 'NOUN', 'I-VP'),\n  ('a', 'DET', 'B-NP'),\n  ('UNK', 'UNK', 'I-NP'),\n  ('in', 'ADP', 'B-PP'),\n  ('sterling', 'NOUN', 'B-NP'),\n  ('over', 'ADP', 'B-PP'),\n  ('the', 'DET', 'B-NP'),\n  ('past', 'NOUN', 'I-NP'),\n  ('week', 'NOUN', 'I-NP'),\n  ('.', '.', 'O')],\n [('but', 'CONJ', 'O'),\n  ('analysts', 'NOUN', 'B-NP'),\n  ('UNK', 'UNK', 'B-VP'),\n  ('underlying', 'VERB', 'B-NP'),\n  ('support', 'NOUN', 'I-NP'),\n  ('for', 'ADP', 'B-PP'),\n  ('sterling', 'NOUN', 'B-NP'),\n  ('has', 'VERB', 'B-VP'),\n  ('been', 'VERB', 'I-VP'),\n  ('eroded', 'VERB', 'I-VP'),\n  ('by', 'ADP', 'B-PP'),\n  ('the', 'DET', 'B-NP'),\n  ('chancellor', 'NOUN', 'I-NP'),\n  (\"'s\", 'PRT', 'B-NP'),\n  ('failure', 'NOUN', 'I-NP'),\n  ('to', 'PRT', 'B-VP'),\n  ('announce', 'NOUN', 'I-VP'),\n  ('any', 'DET', 'B-NP'),\n  ('new', 'ADJ', 'I-NP'),\n  ('policy', 'NOUN', 'I-NP'),\n  ('measures', 'NOUN', 'I-NP'),\n  ('in', 'ADP', 'B-PP'),\n  ('his', 'PRON', 'B-NP'),\n  ('mansion', 'NOUN', 'I-NP'),\n  ('house', 'NOUN', 'I-NP'),\n  ('speech', 'NOUN', 'I-NP'),\n  ('last', 'ADJ', 'B-NP'),\n  ('thursday', 'NOUN', 'I-NP'),\n  ('.', '.', 'O')]]"
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_sentences = replace_low_frequency_words(sentences, filter_count=3)\n",
    "filtered_sentences[:3]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T15:03:07.244053Z",
     "start_time": "2024-02-26T15:03:07.207500Z"
    }
   },
   "id": "cfe0205c24c0aad5"
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [],
   "source": [
    "def create_vocab_index(sentences_with_pos_tags):\n",
    "    def build_index(items, start_index=0):\n",
    "        item_to_index = defaultdict(lambda: len(item_to_index) + start_index)\n",
    "        for item in items:\n",
    "            item_to_index[item]\n",
    "        return dict(item_to_index)\n",
    "\n",
    "    all_words = [word for sentence in sentences_with_pos_tags for word, _, _ in sentence]\n",
    "    all_xpos_tags = [xpos for sentence in sentences_with_pos_tags for _, xpos, _ in sentence]\n",
    "\n",
    "    return build_index(all_words, start_index=1), build_index(all_xpos_tags, start_index=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T15:03:10.093869Z",
     "start_time": "2024-02-26T15:03:10.080909Z"
    }
   },
   "id": "5925e50a09e8b477"
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [],
   "source": [
    "word_to_index, xpos_to_index =create_vocab_index(filtered_sentences)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T15:03:11.254416Z",
     "start_time": "2024-02-26T15:03:11.252779Z"
    }
   },
   "id": "9bf2bc45335214b0"
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6325 13\n"
     ]
    }
   ],
   "source": [
    "print(len(word_to_index), len(xpos_to_index))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T15:03:12.114727Z",
     "start_time": "2024-02-26T15:03:12.102278Z"
    }
   },
   "id": "1c1129ccb365531b"
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [],
   "source": [
    "def convert_to_indexes(filtered_sentences_tags, word_to_index, xpos_to_index):\n",
    "    hidden_states = []\n",
    "    observations = []\n",
    "\n",
    "    for sentence in filtered_sentences_tags:\n",
    "        # if len(sentence) <= 5:\n",
    "        #     continue\n",
    "        sentence_xpos_indexes = [xpos_to_index[xpos] for _, xpos, _ in sentence]\n",
    "        sentence_word_indexes = [word_to_index[word] for word, _, _ in sentence]\n",
    "        \n",
    "        hidden_states.append(sentence_xpos_indexes)\n",
    "        observations.append(sentence_word_indexes)\n",
    "\n",
    "    return hidden_states, observations"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T15:03:13.494295Z",
     "start_time": "2024-02-26T15:03:13.479694Z"
    }
   },
   "id": "20c858c245a3e473"
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [],
   "source": [
    "hidden_states, observations = convert_to_indexes(filtered_sentences, word_to_index, xpos_to_index)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T15:03:40.904059Z",
     "start_time": "2024-02-26T15:03:40.784890Z"
    }
   },
   "id": "a70793c91e963c95"
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 1, 4, 5, 4, 6, 4, 3, 7, 1, 2, 1, 1, 2, 1, 8, 7, 2, 1, 1, 8, 1, 6, 1, 3, 7, 1, 2, 1, 9, 1, 6, 10, 10, 8]\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 16, 20, 21, 18, 22, 8, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 32, 33]\n",
      "-----------------------------\n",
      "[1, 2, 3, 1, 1, 1, 6, 4, 1, 6, 3, 1, 7, 1, 4, 4, 6, 1, 3, 10, 2, 1, 2, 3, 1, 1, 8]\n",
      "[34, 35, 3, 36, 37, 38, 31, 39, 40, 8, 24, 41, 42, 43, 44, 45, 8, 46, 24, 32, 2, 47, 48, 3, 49, 50, 33]\n",
      "-----------------------------\n",
      "[9, 1, 10, 4, 1, 2, 1, 4, 4, 4, 2, 3, 1, 6, 1, 6, 1, 3, 7, 1, 1, 2, 11, 1, 1, 1, 7, 1, 8]\n",
      "[51, 52, 32, 53, 54, 16, 47, 44, 55, 56, 57, 3, 34, 31, 58, 8, 59, 60, 61, 43, 62, 2, 63, 64, 65, 66, 67, 68, 33]\n",
      "-----------------------------\n",
      "[3, 4, 4, 3, 1, 2, 3, 1, 4, 4, 6, 1, 1, 1, 6, 12, 1, 2, 11, 7, 12, 1, 1, 6, 1, 3, 1, 8, 1, 9, 7, 1, 1, 1, 4, 8]\n",
      "[69, 44, 70, 3, 71, 35, 3, 72, 73, 74, 8, 75, 76, 77, 8, 78, 79, 27, 80, 81, 82, 79, 83, 8, 84, 3, 4, 18, 85, 29, 86, 87, 88, 52, 89, 33]\n",
      "-----------------------------\n",
      "[8, 3, 1, 2, 1, 2, 3, 7, 1, 1, 4, 5, 5, 2, 3, 5, 1, 8, 8, 4, 10, 1, 8, 7, 1, 1, 2, 1, 1, 1, 8]\n",
      "[90, 3, 91, 16, 47, 35, 24, 92, 14, 93, 94, 95, 96, 97, 3, 98, 99, 18, 100, 101, 32, 102, 18, 103, 104, 105, 106, 107, 108, 109, 33]\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "for index in range(len(observations[:5])):\n",
    "    print('[' + ', '.join(map(str, hidden_states[:5][index])) + ']')\n",
    "    print('[' + ', '.join(map(str, observations[:5][index])) + ']')\n",
    "    print('-----------------------------')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T15:03:42.213606Z",
     "start_time": "2024-02-26T15:03:42.194711Z"
    }
   },
   "id": "126d26215baf1f9"
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [],
   "source": [
    "def add_noise_to_states(hidden_states, number_states, flip_prob=0.5):\n",
    "    noisy_hidden_states = []\n",
    "    for sequence in hidden_states:\n",
    "        noisy_sequence = []\n",
    "        for state in sequence:\n",
    "            if np.random.rand() < flip_prob:\n",
    "                # Flip the state to a different random state\n",
    "                possible_states = list(range(1, number_states + 1))\n",
    "                possible_states.remove(state)  # Remove the current state from possibilities\n",
    "                new_state = np.random.choice(possible_states)\n",
    "                noisy_sequence.append(new_state)\n",
    "            else:\n",
    "                noisy_sequence.append(state)\n",
    "        noisy_hidden_states.append(noisy_sequence)\n",
    "    return noisy_hidden_states"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T14:55:28.200731Z",
     "start_time": "2024-02-26T14:55:28.194725Z"
    }
   },
   "id": "bd1b13d61dd29869"
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [],
   "source": [
    "noise_level = 0.8\n",
    "noisy_hidden_states = add_noise_to_states(hidden_states, len(xpos_to_index), flip_prob=noise_level)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T15:03:45.831360Z",
     "start_time": "2024-02-26T15:03:45.085215Z"
    }
   },
   "id": "c949f6b0fbf8d6d9"
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "outputs": [],
   "source": [
    "for i in range(len(hidden_states)):\n",
    "    hidden_states[i].insert(0, 0)\n",
    "    noisy_hidden_states[i].insert(0, 0)\n",
    "    observations[i].insert(0, 0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T15:03:48.088520Z",
     "start_time": "2024-02-26T15:03:48.079315Z"
    }
   },
   "id": "94b221ea2b6d38b2"
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 1, 4, 5, 4, 6, 4, 3, 7, 1, 2, 1, 1, 2, 1, 8, 7, 2, 1, 1, 8, 1, 6, 1, 3, 7, 1, 2, 1, 9, 1, 6, 10, 10, 8]\n",
      "[0, 6, 1, 5, 6, 9, 12, 13, 11, 13, 9, 13, 7, 12, 4, 4, 12, 2, 9, 7, 6, 10, 4, 8, 9, 1, 8, 13, 11, 2, 1, 8, 4, 1, 6, 7, 3, 8]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 16, 20, 21, 18, 22, 8, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 32, 33]\n",
      "-----------------------------\n",
      "[0, 1, 2, 3, 1, 1, 1, 6, 4, 1, 6, 3, 1, 7, 1, 4, 4, 6, 1, 3, 10, 2, 1, 2, 3, 1, 1, 8]\n",
      "[0, 3, 3, 11, 10, 7, 11, 8, 7, 3, 10, 7, 1, 1, 10, 10, 4, 8, 5, 2, 7, 5, 4, 1, 9, 2, 9, 4]\n",
      "[0, 34, 35, 3, 36, 37, 38, 31, 39, 40, 8, 24, 41, 42, 43, 44, 45, 8, 46, 24, 32, 2, 47, 48, 3, 49, 50, 33]\n",
      "-----------------------------\n",
      "[0, 9, 1, 10, 4, 1, 2, 1, 4, 4, 4, 2, 3, 1, 6, 1, 6, 1, 3, 7, 1, 1, 2, 11, 1, 1, 1, 7, 1, 8]\n",
      "[0, 9, 7, 10, 1, 7, 9, 5, 13, 4, 5, 9, 1, 1, 2, 7, 4, 3, 3, 8, 10, 8, 10, 1, 1, 8, 7, 11, 11, 9]\n",
      "[0, 51, 52, 32, 53, 54, 16, 47, 44, 55, 56, 57, 3, 34, 31, 58, 8, 59, 60, 61, 43, 62, 2, 63, 64, 65, 66, 67, 68, 33]\n",
      "-----------------------------\n",
      "[0, 3, 4, 4, 3, 1, 2, 3, 1, 4, 4, 6, 1, 1, 1, 6, 12, 1, 2, 11, 7, 12, 1, 1, 6, 1, 3, 1, 8, 1, 9, 7, 1, 1, 1, 4, 8]\n",
      "[0, 3, 6, 7, 5, 12, 2, 10, 1, 8, 4, 3, 1, 4, 13, 6, 10, 6, 11, 4, 12, 2, 10, 3, 8, 5, 7, 1, 1, 8, 12, 10, 10, 12, 3, 12, 13]\n",
      "[0, 69, 44, 70, 3, 71, 35, 3, 72, 73, 74, 8, 75, 76, 77, 8, 78, 79, 27, 80, 81, 82, 79, 83, 8, 84, 3, 4, 18, 85, 29, 86, 87, 88, 52, 89, 33]\n",
      "-----------------------------\n",
      "[0, 8, 3, 1, 2, 1, 2, 3, 7, 1, 1, 4, 5, 5, 2, 3, 5, 1, 8, 8, 4, 10, 1, 8, 7, 1, 1, 2, 1, 1, 1, 8]\n",
      "[0, 8, 10, 1, 1, 7, 9, 10, 12, 5, 11, 2, 4, 9, 11, 2, 3, 1, 9, 6, 9, 8, 6, 11, 1, 3, 3, 3, 9, 3, 8, 4]\n",
      "[0, 90, 3, 91, 16, 47, 35, 24, 92, 14, 93, 94, 95, 96, 97, 3, 98, 99, 18, 100, 101, 32, 102, 18, 103, 104, 105, 106, 107, 108, 109, 33]\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "for index in range(len(observations[:5])):\n",
    "    print('[' + ', '.join(map(str, hidden_states[:5][index])) + ']')\n",
    "    print('[' + ', '.join(map(str, noisy_hidden_states[:5][index])) + ']')\n",
    "    print('[' + ', '.join(map(str, observations[:5][index])) + ']')\n",
    "    print('-----------------------------')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T15:03:48.857829Z",
     "start_time": "2024-02-26T15:03:48.835807Z"
    }
   },
   "id": "c80026e64b269300"
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "outputs": [],
   "source": [
    "file_path = f\"../../data/chunking_synthetic_dataset(noise-{noise_level}).npz\"\n",
    "obs_object = np.array(observations, dtype=object)\n",
    "hid_object = np.array(hidden_states, dtype=object)\n",
    "noisy_hid_object = np.array(noisy_hidden_states, dtype=object)\n",
    "np.savez(file_path, num_states_specific=len(xpos_to_index) + 1, num_obs=len(word_to_index) + 1, observation=obs_object, real_hidden_specific=hid_object, noisy_hidden_specific=noisy_hid_object, noisy_level=noise_level)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T15:03:51.115838Z",
     "start_time": "2024-02-26T15:03:50.919572Z"
    }
   },
   "id": "14b844e9ee846897"
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 0,  5,  2,  3, 13,  2,  8,  8,  2,  3,  3,  1,  2,  3,  1, 11,  2,\n",
      "        11,  2, 11,  2,  3,  8,  2,  8,  2,  3,  2,  3, 13,  2, 11,  2, 11,\n",
      "         2,  3,  1,  2])\n",
      " array([ 0,  5,  2,  3,  3,  3,  1,  2,  3,  1,  2,  3,  1,  3,  1,  8,  2,\n",
      "         2,  3,  3,  1,  2,  5,  2,  3,  1, 13,  2])\n",
      " array([ 0,  5,  3,  1,  1,  8,  2, 11,  8,  2,  5,  2,  3,  1,  8,  8,  2,\n",
      "         3,  3,  3,  1,  8,  2,  3,  3, 13,  2,  3, 11,  2])\n",
      " array([ 0,  3,  8,  2,  3, 13,  2,  3, 13,  2,  8,  2,  3, 13,  8,  2,  1,\n",
      "         8,  2,  3,  1,  8,  2,  8,  2,  3,  3, 13,  2,  6,  2,  3,  1,  1,\n",
      "        11,  8,  2])\n",
      " array([ 0,  5,  3,  1,  2, 11,  2,  3, 13,  8,  8,  2,  3,  3,  2,  3,  8,\n",
      "         2,  8, 11,  2,  3,  8,  2,  3,  1, 13,  2, 11,  8,  8,  2])       ]\n"
     ]
    }
   ],
   "source": [
    "data_path = f\"../../result/chunking-noise-0.9_iter-20_timestamp-0226_150117_state.npz\"\n",
    "loaded_npz = np.load(data_path, allow_pickle=True)\n",
    "sampled_hidden_states = loaded_npz['hidden_state']\n",
    "print(sampled_hidden_states[:5])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T15:04:24.384867Z",
     "start_time": "2024-02-26T15:04:24.347715Z"
    }
   },
   "id": "ed7340e1a06c2d4f"
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "outputs": [
    {
     "data": {
      "text/plain": "8971"
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sampled_hidden_states)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T15:04:28.944483Z",
     "start_time": "2024-02-26T15:04:28.941529Z"
    }
   },
   "id": "514a2c98e1310196"
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "outputs": [],
   "source": [
    "def create_tsv_from_data(data, file_path, pos=True):\n",
    "    # Open the file for writing\n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        for index, sentence in enumerate(data):\n",
    "            for i, (word, _, chunk) in enumerate(sentence):\n",
    "                if pos: \n",
    "                    file.write(f\"{word}\\t{sampled_hidden_states[index][i+1]}\\t{chunk}\\n\")\n",
    "                else: \n",
    "                    file.write(f\"{word}\\t{chunk}\\n\")\n",
    "            file.write(\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T15:04:31.035113Z",
     "start_time": "2024-02-26T15:04:31.012347Z"
    }
   },
   "id": "156e46d5aa5359da"
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "outputs": [],
   "source": [
    "create_tsv_from_data(sentences, \"/Users/binglunli/Desktop/CRF++-0.58/train_file_sampled.txt\")\n",
    "create_tsv_from_data(sentences, \"/Users/binglunli/Desktop/CRF++-0.58/train_file_controlled.txt\", pos=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T15:04:42.493208Z",
     "start_time": "2024-02-26T15:04:42.281772Z"
    }
   },
   "id": "7d889d16bab0b974"
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "text_sentences = read_sentences_with_pos_tags(\"../data/chunking/test.txt\")\n",
    "create_tsv_from_data(text_sentences, \"/Users/binglunli/Desktop/CRF++-0.58/experiment/test_controlled.txt\", pos=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T11:55:34.256859Z",
     "start_time": "2024-02-26T11:55:34.210874Z"
    }
   },
   "id": "3756930a7accacd3"
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [
    "def test_output_accuracy(output_path, truth_col, prediction_col):\n",
    "    truth = []\n",
    "    prediction = []\n",
    "    with open(output_path, 'r', encoding='utf-8') as file: \n",
    "        for line in file: \n",
    "            line = line.replace('\\n', '')       \n",
    "            if line.strip():\n",
    "                fields = line.split('\\t')\n",
    "                # print(fields)\n",
    "                truth.append(fields[truth_col])\n",
    "                prediction.append(fields[prediction_col])\n",
    "            \n",
    "    return np.array(truth), np.array(prediction)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T14:27:32.633579Z",
     "start_time": "2024-02-26T14:27:32.605342Z"
    }
   },
   "id": "6c21c0938da2cafc"
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score\n",
    "def compute_score(true_values, predicted_values):\n",
    "    acc_score = accuracy_score(true_values, predicted_values)\n",
    "    # rec_score = recall_score(true_values, predicted_values, average='weighted')\n",
    "    prec_score = precision_score(true_values, predicted_values, average='weighted')\n",
    "    f1 = f1_score(true_values, predicted_values, average='weighted')\n",
    "    return acc_score, prec_score, f1 "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T15:23:34.388435Z",
     "start_time": "2024-02-26T15:23:34.384803Z"
    }
   },
   "id": "b300dab364a3c4e6"
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/binglunli/Desktop/Uni_Cam/Part II/Project/Implementation/Part_II_Project/projenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": "(0.9277540852087995, 0.9261090960207328, 0.9261159430304706)"
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path = \"/Users/binglunli/Desktop/CRF++-0.58/experiment/output/output_controlled.txt\"\n",
    "truth, prediction = test_output_accuracy(output_path, 1, 2)\n",
    "compute_score(truth, prediction)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T15:23:35.652945Z",
     "start_time": "2024-02-26T15:23:35.525937Z"
    }
   },
   "id": "2d6215d45d810166"
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/binglunli/Desktop/Uni_Cam/Part II/Project/Implementation/Part_II_Project/projenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": "(0.9599383667180277, 0.959634323086229, 0.9597060730112831)"
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path = \"/Users/binglunli/Desktop/CRF++-0.58/experiment/output/output_real.txt\"\n",
    "truth, prediction = test_output_accuracy(output_path, 2, 3)\n",
    "compute_score(truth, prediction)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T15:23:36.663793Z",
     "start_time": "2024-02-26T15:23:36.517617Z"
    }
   },
   "id": "bad8624c2fcbf8b2"
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/binglunli/Desktop/Uni_Cam/Part II/Project/Implementation/Part_II_Project/projenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": "(0.9482689391613247, 0.9469701566552355, 0.9469474964927541)"
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path = \"/Users/binglunli/Desktop/CRF++-0.58/experiment/output/output_sampled.txt\"\n",
    "truth, prediction = test_output_accuracy(output_path, 2, 3)\n",
    "compute_score(truth, prediction)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T15:23:38.497801Z",
     "start_time": "2024-02-26T15:23:37.799121Z"
    }
   },
   "id": "5bfa6c0e9e5da6f4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "projenv",
   "language": "python",
   "display_name": "Part II Project Env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
